{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from ldg.pickle import pickle_read\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence', 'label', 'lemma', 'label_freq_in_train', 'label_1',\n",
       "       'label_2', 'label_3', 'label_4', 'label_5', 'label_6',\n",
       "       ...\n",
       "       'distance_41', 'distance_42', 'distance_43', 'distance_44',\n",
       "       'distance_45', 'distance_46', 'distance_47', 'distance_48',\n",
       "       'distance_49', 'distance_50'],\n",
       "      dtype='object', length=204)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "from bssp.common import paths\n",
    "from bssp.common.config import Config\n",
    "\n",
    "\n",
    "K = 50\n",
    "K_RANGE = range(5,55,5)\n",
    "\n",
    "cfg = Config(\n",
    "    \"semcor\",\n",
    "    embedding_model=\"bert-base-cased\",\n",
    "    override_weights_path=None,\n",
    "    metric=\"cosine\",\n",
    "    top_n=50,\n",
    "    query_n=1,\n",
    "    bert_layers=[7],\n",
    ")\n",
    "\n",
    "def override_config(cfg, metric, model, query_n, bert_layers, override_weights_path):\n",
    "    cfg2 = copy.copy(cfg)\n",
    "    if metric is not None:\n",
    "        cfg2.metric = metric\n",
    "    if model:\n",
    "        cfg2.embedding_model = model \n",
    "    if query_n:\n",
    "        cfg2.query_n = query_n\n",
    "    if bert_layers:\n",
    "        cfg2.bert_layers = bert_layers\n",
    "    if override_weights_path:\n",
    "        cfg2.override_weights_path = override_weights_path\n",
    "    return cfg2\n",
    "\n",
    "def read_score(min_train_freq, max_train_freq, min_rarity, max_rarity, eval, metric=None, model=None, query_n=None, bert_layers=None, override_weights_path=None):\n",
    "    cfg2 = override_config(cfg, metric=metric, model=model, query_n=query_n, bert_layers=bert_layers, override_weights_path=override_weights_path)\n",
    "    filepath = paths.bucketed_metric_at_k_path(\n",
    "        cfg2,\n",
    "        min_train_freq=min_train_freq,\n",
    "        max_train_freq=max_train_freq,\n",
    "        min_rarity=min_rarity,\n",
    "        max_rarity=max_rarity,\n",
    "        ext=eval\n",
    "    )\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(\"WARNING: not found: \", filepath)\n",
    "        return None\n",
    "    return pickle_read(filepath)\n",
    "\n",
    "def read_data(metric=None, model=None, query_n=None, bert_layers=None, override_weights_path=None):\n",
    "    cfg2 = override_config(cfg, metric=metric, model=model, query_n=query_n, bert_layers=bert_layers, override_weights_path=override_weights_path)\n",
    "    filepath = paths.predictions_tsv_path(cfg2)\n",
    "    data = pd.read_csv(filepath, sep='\\t')\n",
    "    return data\n",
    "\n",
    "cosine_data = read_data('cosine', bert_layers=[7])#, override_weights_path=\"models/bert-base-cased_250.pt\")\n",
    "cosine_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyzize(scores_dict, key='synset'):\n",
    "    x, y, z = [], [], []\n",
    "    for cutoff, p_at_k_dict in scores_dict.items():\n",
    "        for k, scores in p_at_k_dict.items():\n",
    "            if k > cutoff and False:\n",
    "                continue\n",
    "            x.append(cutoff)\n",
    "            y.append(k)\n",
    "            z.append(scores[key])\n",
    "    return x, y, z\n",
    "    \n",
    "def plot_p_vs_k(p_at_k_dict, p_at_k_dict_2=None, key='synset'):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    ax = plt.axes()\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel(f'{key} precision')\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    k, scores = list(zip(*p_at_k_dict.items()))\n",
    "    scores = [x[key] for x in scores]\n",
    "    k = list(k)\n",
    "    ax.scatter(x=k, y=scores, c=scores)\n",
    "    if p_at_k_dict_2:\n",
    "        k, scores = list(zip(*p_at_k_dict_2.items()))\n",
    "        scores = [x[key] for x in scores]\n",
    "        k = list(k)       \n",
    "        ax.scatter(x=k, y=scores, c=scores, marker='x')\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "TEMPSTATE = 0\n",
    "def plot_grid(configs, key='label', evals=['rec'], metric='cosine', query_n=1):\n",
    "    global TEMPSTATE\n",
    "    fig, axs = plt.subplots(4,5,figsize=(20,12))\n",
    "    plt.subplots_adjust(hspace=1.0, wspace=0.5)\n",
    "    #fig.suptitle(\"Microaveraged \" + (\"Recall\" if evals[0]=='rec' \n",
    "    #              else \"Oracle Recall\" if evals[0]=='orec'\n",
    "    #              else \"Truncated Recall\" if evals[0]=='trec'\n",
    "    #              else \"Precision\") + \" at K\")\n",
    "    \n",
    "    i = 0\n",
    "    for min_train_freq, max_train_freq in cfg.train_freq_buckets:\n",
    "        for min_rarity, max_rarity in cfg.prevalence_buckets:\n",
    "            ax = axs[i//5][i%5]\n",
    "            i += 1\n",
    "            lemmas = pickle_read(paths.bucketed_metric_at_k_path(\n",
    "                cfg,\n",
    "                min_train_freq=min_train_freq, \n",
    "                max_train_freq=max_train_freq, \n",
    "                min_rarity=min_rarity, \n",
    "                max_rarity=max_rarity, \n",
    "                ext='lemmas', \n",
    "            ))\n",
    "            instance_count = pickle_read(paths.bucketed_metric_at_k_path(\n",
    "                cfg,\n",
    "                min_train_freq=min_train_freq, \n",
    "                max_train_freq=max_train_freq, \n",
    "                min_rarity=min_rarity, \n",
    "                max_rarity=max_rarity, \n",
    "                ext='count', \n",
    "            ))\n",
    "            \n",
    "            tstr = f'{min_train_freq}≤c<{max_train_freq}, {min_rarity}≤prvl<{max_rarity}\\nlems={len(lemmas) if lemmas else 0}, n={instance_count}'\n",
    "            ax.set_title(tstr)\n",
    "            print(tstr) \n",
    "            print(lemmas)\n",
    "            #ax.set_ylim(0.2, 0.8)\n",
    "            ax.set_ylim(0, 1.1)\n",
    "            \n",
    "            for c in configs:\n",
    "                metric_ = c.get('metric') or metric\n",
    "                color_ = c.get('color') or 'pink'\n",
    "                eval_ = c['eval']\n",
    "                query_n_ = c.get('query_n') or query_n\n",
    "                bert_layers_ = c.get('bert_layers') or None\n",
    "                override_weights_path_ = c.get('override_weights_path', None)\n",
    "            \n",
    "                scores = read_score(\n",
    "                    eval=eval_, \n",
    "                    min_train_freq=min_train_freq, \n",
    "                    max_train_freq=max_train_freq, \n",
    "                    min_rarity=min_rarity, \n",
    "                    max_rarity=max_rarity,\n",
    "                    metric=metric_,\n",
    "                    query_n=query_n_,\n",
    "                    bert_layers=bert_layers_,\n",
    "                    override_weights_path=override_weights_path_\n",
    "                )\n",
    "                if scores is None:\n",
    "                    continue\n",
    "                k, scores = list(zip(*scores.items()))\n",
    "                scores = [x[key] for x in scores]\n",
    "                k = list(k)\n",
    "                #ax.scatter(x=k, y=scores, c=scores)\n",
    "                ax.plot(k, scores, color_)\n",
    "        \n",
    "        \n",
    "    #if TEMPSTATE == 0:\n",
    "    #    plt.savefig('/home/luke/tmp/recall_inter.pdf')\n",
    "    #    TEMPSTATE += 1\n",
    "    #else:\n",
    "    #    plt.savefig('/home/luke/tmp/precision_inter.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "for i in range(2):\n",
    "    s = ''\n",
    "    if i == 1:\n",
    "        s = 'p'\n",
    "    plot_grid([\n",
    "        # layers --------------------------------------------------------------------------------\n",
    "        dict(metric='baseline', eval=f'{s}rec', color='b--', bert_layers=[7]),\n",
    "        dict(metric='baseline', eval=f'o{s}rec', color='y--', bert_layers=[7]),\n",
    "        \n",
    "        dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[7], color='red'),\n",
    "        dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[7], color='blue')#, override_weights_path=\"models/bert-base-cased_250.pt\"),\n",
    "        \n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=2, bert_layers=[7], color='green'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=3, bert_layers=[7], color='blue'),\n",
    "        \n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[0], color='red'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[6], color='orange'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[10], color='green'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=5, bert_layers=[0], color='r--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=5, bert_layers=[6], color='b--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=5, bert_layers=[10], color='g--'),\n",
    "        \n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[6],  color='r--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[7],  color='y--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[8],  color='g--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[9],  color='b--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[10], color='c--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[11], color='v--'),\n",
    "        \n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[6], color='red'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=3, bert_layers=[6], color='green'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=5, bert_layers=[6], color='blue'),\n",
    "        \n",
    "        #dict(metric='baseline', eval=f'o{s}rec', color='y--', query_category='nota'),\n",
    "        #dict(metric='baseline', eval=f'{s}rec', color='m--', query_category='nota'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[6], color='r--', query_category='nota'),\n",
    "        ##\n",
    "        #dict(metric='baseline', eval=f'o{s}rec', color='g', query_category='non-nota'),\n",
    "        #dict(metric='baseline', eval=f'{s}rec', color='c', query_category='non-nota'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=3, bert_layers=[6], color='b', query_category='non-nota'),\n",
    "        \n",
    "        #dict(metric='baseline', eval=f'o{s}rec', color='y--', query_category='non-nota', pos='all'),\n",
    "        #dict(metric='baseline', eval=f'{s}rec', color='m--', query_category='non-nota', pos='all'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[6], color='r--', query_category='non-nota', pos='all'),\n",
    "        ##\n",
    "        #dict(metric='baseline', eval=f'o{s}rec', color='g', query_category='non-nota', pos='all'),\n",
    "        #dict(metric='baseline', eval=f'{s}rec', color='c', query_category='non-nota', pos='all'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=3, bert_layers=[6], color='b', query_category='non-nota', pos='all'),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bssp.common import paths\n",
    "\n",
    "\n",
    "for query_n in [1]:\n",
    "    print(query_n)\n",
    "    for metric in ['cosine','euclidean','baseline']:\n",
    "        for min_train_freq, max_train_freq in TRAIN_FREQ_BUCKETS:\n",
    "            for min_rarity, max_rarity in PREVALENCE_BUCKETS:\n",
    "                for bert_layer in range(12):\n",
    "                    extra = {}\n",
    "                    if metric != 'baseline':\n",
    "                        extra['bert_layers'] = [bert_layer]\n",
    "                    means = read_score(\n",
    "                        query_category='non-nota',\n",
    "                        pos='all',\n",
    "                        eval='means', \n",
    "                        min_train_freq=min_train_freq, \n",
    "                        max_train_freq=max_train_freq, \n",
    "                        min_rarity=min_rarity, \n",
    "                        max_rarity=max_rarity,\n",
    "                        metric=metric,\n",
    "                        query_n=query_n,\n",
    "                        **extra\n",
    "                    )\n",
    "                    if metric == 'baseline':\n",
    "                        continue\n",
    "                    #print(means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data columns:\n",
    "# sentence: original sentence\n",
    "# label, lemma, synset, label_freq_in_train\n",
    "# label_i\n",
    "# synset_i\n",
    "# lemma_i\n",
    "# distance_i\n",
    "list(cosine_data.keys())\n",
    "\n",
    "def distance_correctness_corr(data, key='label'):\n",
    "    \n",
    "    plt.figure(figsize=(8,5))\n",
    "    ax = plt.axes()\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel(f'distance correlated with correctness')\n",
    "    \n",
    "    df = data.copy()\n",
    "    for i in range(1,K+1):\n",
    "        df['correct'] = df[f'{key}_{i}'] == df[f'{key}']\n",
    "        r = df[['correct', f'distance_{i}']].corr()['correct'][1]\n",
    "        ax.scatter(i, r, color='blue')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def distance_correctness_histogram(data, key='label'):\n",
    "    df = data.copy()\n",
    "    df['first_correct'] = df[f'{key}_1'] == df[f'{key}']\n",
    "    df[['first_correct', 'distance_1']].pivot(columns='first_correct').distance_1.plot.hist(stacked=True, bins=50)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "distance_correctness_corr(cosine_data)\n",
    "#distance_correctness_histogram(euclidean_data[euclidean_data.pos=='r'])\n",
    "#distance_correctness_histogram(cosine_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_scores[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
