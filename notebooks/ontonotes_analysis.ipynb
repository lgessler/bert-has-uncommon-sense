{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from ldg.pickle import pickle_read\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cache/ontonotes_cosine_q1_predictions/bert-base-cased_0.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0aa36e30508b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mcosine_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mcosine_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-0aa36e30508b>\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(metric, model, query_n, bert_layers)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions_tsv_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ontonotes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbert_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cache/ontonotes_cosine_q1_predictions/bert-base-cased_0.tsv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bssp.common import paths\n",
    "\n",
    "K = 50\n",
    "K_RANGE = range(5,55,5)\n",
    "\n",
    "def read_score(min_train_freq, max_train_freq, min_rarity, max_rarity, eval, metric='cosine', model='bert-base-cased', query_n=1, query_category='all', pos='all', bert_layers=None):\n",
    "    filepath = paths.bucketed_metric_at_k_path(\n",
    "        distance_metric=metric,\n",
    "        query_n=query_n,\n",
    "        embedding_name=model,\n",
    "        min_train_freq=min_train_freq,\n",
    "        max_train_freq=max_train_freq,\n",
    "        min_rarity=min_rarity,\n",
    "        max_rarity=max_rarity,\n",
    "        ext=eval,\n",
    "        query_category=query_category,\n",
    "        pos=pos,\n",
    "        bert_layers=bert_layers\n",
    "    )\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(\"WARNING: not found: \", filepath)\n",
    "        return None\n",
    "    return pickle_read(filepath)\n",
    "\n",
    "def read_data(metric, model='bert-base-cased', query_n=1, bert_layers=None):\n",
    "    filepath = paths.predictions_tsv_path('ontonotes', metric, embedding_name=model, query_n=query_n, bert_layers=bert_layers)\n",
    "    data = pd.read_csv(filepath, sep='\\t')\n",
    "    return data\n",
    "\n",
    "cosine_data = read_data('cosine', bert_layers=[0])\n",
    "cosine_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bssp.common.const import TRAIN_FREQ_BUCKETS, PREVALENCE_BUCKETS\n",
    "\n",
    "def xyzize(scores_dict, key='synset'):\n",
    "    x, y, z = [], [], []\n",
    "    for cutoff, p_at_k_dict in scores_dict.items():\n",
    "        for k, scores in p_at_k_dict.items():\n",
    "            if k > cutoff and False:\n",
    "                continue\n",
    "            x.append(cutoff)\n",
    "            y.append(k)\n",
    "            z.append(scores[key])\n",
    "    return x, y, z\n",
    "\n",
    "def plot_surface(scores_dict, key='synset'):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    ax = plt.axes(projection='3d')\n",
    "    ax.set_xlabel('occurrence cutoff')\n",
    "    ax.set_ylabel('k')\n",
    "    ax.set_zlabel(f'{key} recall')\n",
    "    #ax.set_zlim(0.3, 1)\n",
    "    x, y, z = xyzize(scores_dict, key=key)\n",
    "    ax.scatter(x, y, z, c=z, cmap='viridis', linewidth=0.5)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_p_vs_k(p_at_k_dict, p_at_k_dict_2=None, key='synset'):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    ax = plt.axes()\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel(f'{key} precision')\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    k, scores = list(zip(*p_at_k_dict.items()))\n",
    "    scores = [x[key] for x in scores]\n",
    "    k = list(k)\n",
    "    ax.scatter(x=k, y=scores, c=scores)\n",
    "    if p_at_k_dict_2:\n",
    "        k, scores = list(zip(*p_at_k_dict_2.items()))\n",
    "        scores = [x[key] for x in scores]\n",
    "        k = list(k)       \n",
    "        ax.scatter(x=k, y=scores, c=scores, marker='x')\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "TEMPSTATE = 0\n",
    "def plot_grid(configs, key='label', evals=['rec'], metric='cosine', query_n=1, query_category='non-nota', pos='all'):\n",
    "    global TEMPSTATE\n",
    "    fig, axs = plt.subplots(4,5,figsize=(20,12))\n",
    "    plt.subplots_adjust(hspace=1.0, wspace=0.5)\n",
    "    #fig.suptitle(\"Microaveraged \" + (\"Recall\" if evals[0]=='rec' \n",
    "    #              else \"Oracle Recall\" if evals[0]=='orec'\n",
    "    #              else \"Truncated Recall\" if evals[0]=='trec'\n",
    "    #              else \"Precision\") + \" at K\")\n",
    "    \n",
    "    i = 0\n",
    "    for min_train_freq, max_train_freq in TRAIN_FREQ_BUCKETS:\n",
    "        for min_rarity, max_rarity in PREVALENCE_BUCKETS:\n",
    "            ax = axs[i//5][i%5]\n",
    "            i += 1\n",
    "            ax.set_title(f'{min_train_freq}≤c<{max_train_freq}\\n{min_rarity}≤prvl<{max_rarity}')\n",
    "            #ax.set_ylim(0.2, 0.8)\n",
    "            ax.set_ylim(0, 1.1)\n",
    "            \n",
    "            for c in configs:\n",
    "                metric_ = c.get('metric') or metric\n",
    "                color_ = c.get('color') or 'pink'\n",
    "                eval_ = c['eval']\n",
    "                query_n_ = c.get('query_n') or query_n\n",
    "                bert_layers_ = c.get('bert_layers') or None\n",
    "                query_category_ = c.get('query_category') or query_category\n",
    "                pos_ = c.get('pos') or pos\n",
    "            \n",
    "                scores = read_score(\n",
    "                    eval=eval_, \n",
    "                    min_train_freq=min_train_freq, \n",
    "                    max_train_freq=max_train_freq, \n",
    "                    min_rarity=min_rarity, \n",
    "                    max_rarity=max_rarity,\n",
    "                    metric=metric_,\n",
    "                    query_n=query_n_,\n",
    "                    query_category=query_category_,\n",
    "                    pos=pos_,\n",
    "                    bert_layers=bert_layers_\n",
    "                )\n",
    "                if scores is None:\n",
    "                    continue\n",
    "                k, scores = list(zip(*scores.items()))\n",
    "                scores = [x[key] for x in scores]\n",
    "                k = list(k)\n",
    "                #ax.scatter(x=k, y=scores, c=scores)\n",
    "                ax.plot(k, scores, color_)\n",
    "        \n",
    "        \n",
    "    #if TEMPSTATE == 0:\n",
    "    #    plt.savefig('/home/luke/tmp/recall_inter.pdf')\n",
    "    #    TEMPSTATE += 1\n",
    "    #else:\n",
    "    #    plt.savefig('/home/luke/tmp/precision_inter.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "#score = read_score(\n",
    "#    freq_cutoff=5,\n",
    "#    rarity=5,\n",
    "#    eval='prec'\n",
    "#)\n",
    "#plot_p_vs_k(score, key='synset')\n",
    "#plot_p_vs_k_grid(key='label', evals=['prec','rec'])\n",
    "#plot_p_vs_k_grid(key='label', evals=['rec', 'orec'])\n",
    "#plot_p_vs_k_grid(key='label', evals=['prec'])\n",
    "#score\n",
    "\n",
    "#plot_grid([\n",
    "#    dict(metric='baseline', eval='rec', color='b'),\n",
    "#    dict(metric='baseline', eval='orec', color='y-'),\n",
    "#    dict(metric='cosine', eval='rec', color='red', query_n=1, bert_layers=[3]),\n",
    "#    dict(metric='cosine', eval='rec', color='orange', query_n=3, bert_layers=[3]),\n",
    "#    dict(metric='cosine', eval='rec', color='yellow', query_n=5, bert_layers=[3]),\n",
    "#])\n",
    "#plot_grid([\n",
    "#    dict(metric='baseline', eval='prec', color='b'),\n",
    "#    dict(metric='cosine', eval='prec', color='red', query_n=1, bert_layers=[3]),\n",
    "#    dict(metric='cosine', eval='prec', color='orange', query_n=3, bert_layers=[3]),\n",
    "#    dict(metric='cosine', eval='prec', color='yellow', query_n=5, bert_layers=[3]),\n",
    "#])\n",
    "\n",
    "for i in range(2):\n",
    "    s = ''\n",
    "    if i == 1:\n",
    "        s = 'p'\n",
    "    plot_grid([\n",
    "        # layers --------------------------------------------------------------------------------\n",
    "        dict(metric='baseline', eval=f'{s}rec', color='b--'),\n",
    "        dict(metric='baseline', eval=f'o{s}rec', color='y--'),\n",
    "        \n",
    "        dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[0], color='red'),\n",
    "        dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[6], color='orange'),\n",
    "        dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[10], color='green'),\n",
    "        dict(metric='cosine', eval=f'{s}rec', query_n=5, bert_layers=[0], color='r--'),\n",
    "        dict(metric='cosine', eval=f'{s}rec', query_n=5, bert_layers=[6], color='b--'),\n",
    "        dict(metric='cosine', eval=f'{s}rec', query_n=5, bert_layers=[10], color='g--'),\n",
    "        \n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[6],  color='r--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[7],  color='y--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[8],  color='g--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[9],  color='b--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[10], color='c--'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[11], color='v--'),\n",
    "        \n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[6], color='red'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=3, bert_layers=[6], color='green'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=5, bert_layers=[6], color='blue'),\n",
    "        \n",
    "        #dict(metric='baseline', eval=f'o{s}rec', color='y--', query_category='nota'),\n",
    "        #dict(metric='baseline', eval=f'{s}rec', color='m--', query_category='nota'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[6], color='r--', query_category='nota'),\n",
    "        ##\n",
    "        #dict(metric='baseline', eval=f'o{s}rec', color='g', query_category='non-nota'),\n",
    "        #dict(metric='baseline', eval=f'{s}rec', color='c', query_category='non-nota'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=3, bert_layers=[6], color='b', query_category='non-nota'),\n",
    "        \n",
    "        #dict(metric='baseline', eval=f'o{s}rec', color='y--', query_category='non-nota', pos='all'),\n",
    "        #dict(metric='baseline', eval=f'{s}rec', color='m--', query_category='non-nota', pos='all'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=1, bert_layers=[6], color='r--', query_category='non-nota', pos='all'),\n",
    "        ##\n",
    "        #dict(metric='baseline', eval=f'o{s}rec', color='g', query_category='non-nota', pos='all'),\n",
    "        #dict(metric='baseline', eval=f'{s}rec', color='c', query_category='non-nota', pos='all'),\n",
    "        #dict(metric='cosine', eval=f'{s}rec', query_n=3, bert_layers=[6], color='b', query_category='non-nota', pos='all'),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bssp.common import paths\n",
    "\n",
    "\n",
    "for query_n in [1]:\n",
    "    print(query_n)\n",
    "    for metric in ['cosine','euclidean','baseline']:\n",
    "        for min_train_freq, max_train_freq in TRAIN_FREQ_BUCKETS:\n",
    "            for min_rarity, max_rarity in PREVALENCE_BUCKETS:\n",
    "                for bert_layer in range(12):\n",
    "                    extra = {}\n",
    "                    if metric != 'baseline':\n",
    "                        extra['bert_layers'] = [bert_layer]\n",
    "                    means = read_score(\n",
    "                        query_category='non-nota',\n",
    "                        pos='all',\n",
    "                        eval='means', \n",
    "                        min_train_freq=min_train_freq, \n",
    "                        max_train_freq=max_train_freq, \n",
    "                        min_rarity=min_rarity, \n",
    "                        max_rarity=max_rarity,\n",
    "                        metric=metric,\n",
    "                        query_n=query_n,\n",
    "                        **extra\n",
    "                    )\n",
    "                    if metric == 'baseline':\n",
    "                        continue\n",
    "                    #print(means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data columns:\n",
    "# sentence: original sentence\n",
    "# label, lemma, synset, label_freq_in_train\n",
    "# label_i\n",
    "# synset_i\n",
    "# lemma_i\n",
    "# distance_i\n",
    "list(cosine_data.keys())\n",
    "\n",
    "def distance_correctness_corr(data, key='label'):\n",
    "    \n",
    "    plt.figure(figsize=(8,5))\n",
    "    ax = plt.axes()\n",
    "    ax.set_xlabel('k')\n",
    "    ax.set_ylabel(f'distance correlated with correctness')\n",
    "    \n",
    "    df = data.copy()\n",
    "    for i in range(1,K+1):\n",
    "        df['correct'] = df[f'{key}_{i}'] == df[f'{key}']\n",
    "        r = df[['correct', f'distance_{i}']].corr()['correct'][1]\n",
    "        ax.scatter(i, r, color='blue')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def distance_correctness_histogram(data, key='label'):\n",
    "    df = data.copy()\n",
    "    df['first_correct'] = df[f'{key}_1'] == df[f'{key}']\n",
    "    df[['first_correct', 'distance_1']].pivot(columns='first_correct').distance_1.plot.hist(stacked=True, bins=50)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "distance_correctness_corr(cosine_data)\n",
    "#distance_correctness_histogram(euclidean_data[euclidean_data.pos=='r'])\n",
    "#distance_correctness_histogram(cosine_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_scores[5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
